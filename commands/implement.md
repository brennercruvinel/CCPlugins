# Smart Implementation Engine

I'll intelligently implement features from any source - web URLs, local folders, or multiple references - adapting them perfectly to your project's architecture.

Arguments: `$ARGUMENTS` - URLs, paths, or descriptions of what to implement

## Strategic Analysis

<think>
Let me analyze what type of implementation this is:

1. **Source Type Detection**
   - Is this a web URL with source code?
   - Is this a code sharing platform URL?
   - Is this a local path? (starts with ./ or ../ or /)
   - Is this a description for me to research?
   - Are there multiple sources to combine?

2. **Implementation Approach**
   - Single file to adapt?
   - Multiple files to integrate?
   - Pattern to implement?
   - Library to migrate?

3. **My Capabilities**
   - I can fetch web content with WebFetch
   - I can read local files with Read
   - I can analyze code patterns with Grep
   - I can create adapted implementations

4. **Project Context Needed**
   - What's the target location?
   - What patterns should I follow?
   - What to avoid or replace?
</think>

Based on what you've provided, I'll analyze and adapt the implementation.

## Platform-Specific Import Strategies

I recognize and handle ALL code sharing platforms intelligently:

### Version Control Platforms
When you provide repository URLs (github.com, gitlab.com, bitbucket.org, etc.):
- **Full Repository**: Clone and analyze entire codebase structure
- **Specific File**: Fetch raw content directly  
- **Folder/Directory**: Map all files in that path
- **Gist/Snippet**: Extract and adapt the code fragment
- **Branch/Tag/Commit**: Get specific version of code

### Interactive Code Platforms  
For live coding environments (codepen.io, jsfiddle.net, codesandbox.io, etc.):
- **Parse embed structure**: Extract HTML/CSS/code sections
- **Handle dependencies**: Detect external libraries used
- **Preserve functionality**: Maintain interactive behavior
- **Clean extraction**: Remove platform-specific wrappers

### Online IDEs & Notebooks
From cloud development environments (replit.com, stackblitz.com, colab.research.google.com, etc.):
- **Project structure**: Download full project tree
- **Environment config**: Capture setup and dependencies
- **Multi-file projects**: Preserve file relationships
- **Notebook cells**: Extract code and documentation

### Documentation & Tutorial Sites
When implementing from learning resources:
- **Code blocks**: Extract from tutorials and guides
- **Interactive examples**: Pull from documentation
- **Step-by-step guides**: Follow implementation sequence
- **Community solutions**: Adapt from Q&A platforms

### Package Registries
For library/package sources from any registry:
- **Source exploration**: Analyze package internals
- **Example extraction**: Find usage patterns
- **Version comparison**: Check compatibility
- **Dependency mapping**: Find equivalents in your project

### Local Sources
For files on your machine:
- **Single file**: Direct implementation
- **Project folder**: Full analysis of structure
- **Archived code**: Extract and modernize
- **Legacy systems**: Update patterns to current standards

### Mixed Sources Strategy
When you provide multiple URLs/paths:
1. Analyze each source's unique features
2. Identify complementary functionality
3. Merge intelligently without duplication
4. Create unified, optimized implementation

## SPECIAL CASE: Implementation Plans in Markdown

When you provide a .md file (like documentation.md), I understand this is an IMPLEMENTATION PLAN:

1. **Read the Plan Document**
   - Understand the overall goal
   - Identify all tasks/checklist items
   - Note any specific requirements

2. **Analyze Current Progress**
   - Check each checklist item: Done? Partially done? Not started?
   - Use Grep/Read to verify what's already implemented
   - Map plan items to actual code/files

3. **Continue Implementation**
   - Start from where the plan left off
   - NEVER redo completed work
   - Check off items as I complete them
   - Update progress in the plan

4. **Smart Verification**
   - Before implementing: "Does this already exist?"
   - After implementing: "Did I complete this correctly?"
   - Continuous validation against the plan

## MY COMMITMENT: Complete Professional Analysis

I will:
- Read EVERY code file in EVERY directory
- Never skip files or read partially
- Analyze actual implementation, not assumptions
- Provide detailed technical understanding
- Count and report total files analyzed

## IMPORTANT: Complete File Reading

I will ALWAYS read files completely:
- Read tool: Used WITHOUT limit parameter - reads ENTIRE file
- WebFetch tool: Instructed to read ALL content, no truncation
- No summarization: Complete code, not snippets
- Full analysis: Every line of every file

## Source Analysis - EXHAUSTIVE CODE EXAMINATION

I'll analyze EVERY SINGLE FILE in EVERY repository:

**STEP 1: Map ENTIRE Repository Structure**
```
For EACH repository provided:
1. Use Glob "**/*.*" to find EVERY file
2. List ALL directories and subdirectories
3. Count total files to ensure nothing missed
4. Create complete file tree
```

**STEP 2: Systematic File Reading**
```
For EVERY code file found:
- Read ENTIRE file (no limit parameter)
- Components: Read every component file completely
- Services: Read all service implementations
- Utils: Read every utility function
- Tests: Read test files to understand usage
- Configs: Read all configuration files
- Routes: Read all routing/endpoint files
```

**STEP 3: Deep Component Analysis**
```
For component-based apps:
- Read EVERY component file in components/
- Understand props, state, methods
- Map component relationships
- Analyze data flow between components
- Check how components communicate
```

**STEP 4: Architecture Reconstruction**
```
From actual code reading:
- Entry points (main, index, app files)
- Core business logic location
- Data models and schemas
- API endpoints and handlers
- State management approach
- Dependency injection patterns
- Error handling strategies
```

**STEP 5: Cross-Repository Analysis**
```
When multiple repos provided:
- Compare architectures
- Identify best practices from each
- Find reusable patterns
- Understand different approaches
- Extract most efficient solutions
```

## Project Understanding

First, I'll analyze your project to understand:
- File organization patterns
- Naming conventions
- Technology stack
- Code style preferences
- **COMPLETE dependency files** (Read WITHOUT limit parameter)
- **FULL lock files** (Read WITHOUT limit parameter)
- **Build configuration** (Read WITHOUT limit parameter)
- **ALL documentation** (Read WITHOUT limit parameter)

## Dependency & Compatibility Analysis

<think>
Critical checks before implementation:

1. **Package Compatibility**
   - What versions are already installed?
   - Will new dependencies conflict?
   - Are there better alternatives already in the project?
   - Can I reuse existing packages instead of adding new ones?

2. **Best Practices Alignment**
   - Does this follow current industry standards?
   - Are there security concerns with dependencies?
   - Is this pattern still recommended or deprecated?
   - What do the official docs suggest now?

3. **Performance Considerations**
   - Bundle size impact?
   - Runtime performance implications?
   - Better native alternatives available?
   - Tree-shaking compatibility?
</think>

I'll check your current dependencies and ensure compatibility:
- Read ENTIRE dependency files (no line limits)
- Analyze COMPLETE dependency tree
- Check FULL documentation of existing packages
- Read ALL config files completely (no truncation)

## Adaptation Strategy

<think>
Based on the source and target analysis, I need to:

1. **Smart Dependency Mapping**
   - Map source dependencies to your existing ones
   - Use your utilities instead of adding new ones
   - Convert patterns to match your project
   - Check for equivalent functionality

2. **Transform Code**
   - Match your established patterns
   - Use your existing utilities
   - Follow your error handling approach
   - Maintain your state management style

3. **Ensure Quality**
   - Follow your project's code quality standards
   - Match your testing patterns
   - Use your linting rules
   - Apply your security practices
</think>

## Implementation Process

I'll adapt the source code by:

1. **Pre-Implementation Checks**
   - Verify all dependencies are compatible
   - Check for duplicate functionality
   - Validate against your lint rules
   - Ensure no security issues

2. **Smart Adaptation**
   ```
   Example transformations:
   - External date library → Your existing date solution
   - Legacy HTTP calls → Your HTTP client
   - Outdated patterns → Modern equivalents
   - Old module system → Your module system
   ```

3. **Quality Assurance**
   - Match your project's type system (if any)
   - Follow your linting rules
   - Use your test patterns
   - Apply your code formatting

4. **Best Practices Application**
   - Modern syntax appropriate for your project
   - Proper error handling for your stack
   - Accessibility considerations
   - Performance optimizations

## Execution Approach

I'll proceed step by step:

1. **Fetch and analyze** the source
2. **Understand** your project patterns
3. **Create** adapted implementation
4. **Verify** it fits your architecture
5. **Test** the integration

## Common Use Cases

### 1. Single Source Implementation
Provide a URL or path to analyze and adapt the code to your project.

### 2. Multiple Sources Combination
Provide multiple URLs or paths to intelligently merge features from different sources.

### 3. Research and Implement
Describe what you need and I'll research best practices and implement an optimized version.

### 4. Local Folder Integration
Provide local paths to analyze and integrate existing code.

### 5. Library Migration
Specify what you're migrating from and to, and I'll help with the transition.

### 6. Implementation Plan Execution
Provide a .md file with implementation plan/checklist and I'll:
- Analyze what's been done
- Continue from where it stopped
- Never duplicate completed work
- Update progress as I go

## Smart URL Pattern Recognition

I automatically detect and handle various URL patterns:

### Repository URLs
```
https://github.com/user/repo → Full repository analysis
https://github.com/user/repo/tree/main/src → Specific folder
https://github.com/user/repo/blob/main/filename → Single file
https://gitlab.com/user/project/-/tree/main → GitLab structure
https://bitbucket.org/user/repo/src → Bitbucket format
```

### Code Playground URLs
```
https://codepen.io/user/pen/abc123 → Extract pen code
https://jsfiddle.net/user/abc123/ → Parse fiddle structure
https://codesandbox.io/s/project-name → Download sandbox
https://stackblitz.com/edit/project → Extract project files
https://replit.com/@user/project → Fetch repl content
```

### Raw Content URLs
```
https://raw.githubusercontent.com/... → Direct file content
https://gist.github.com/... → Gist content
https://pastebin.com/... → Text content
Any URL ending in code file extension → Direct fetch
```

### Special Handling
- **Private repos**: I'll guide you to provide accessible content
- **Authentication required**: Instructions for providing access
- **Large repositories**: Smart partial cloning strategies
- **Binary files**: Skip non-text content automatically

## What I Actually Do

1. **EXHAUSTIVE Code Analysis**
   - Use Glob "**/*" to find EVERY file in EVERY directory
   - Read EACH file completely (no limits, no skipping)
   - Map entire application architecture from code
   - Understand every feature implementation
   - Count files read to ensure completeness

2. **Intelligent Fetch**
   - Use WebFetch for URLs with prompt: "Read ENTIRE file content, ALL lines, no summarization"
   - Read local files without limit parameter
   - Extract complete code, not summaries or snippets
   - Analyze full documentation and configuration files

3. **Dependency Resolution**
   ```
   Generic approach:
   - Source needs library X → You have library Y → Use Y
   - Source uses old patterns → Convert to your patterns
   - Source needs utility Z → You have equivalent → Use yours
   - Source uses deprecated features → Use modern alternatives
   ```

4. **Quality Implementation**
   - No unnecessary dependencies
   - Reuse your existing utilities
   - Follow your exact patterns
   - Modern, secure, performant code

5. **Validation**
   - Would this pass your CI/CD?
   - Does it match your code review standards?
   - Is it using best practices from 2025?
   - Will it scale with your application?

## Example Usage Patterns

### Single Source Examples
```bash
# From version control
/implement https://github.com/user/awesome-feature

# From code playground  
/implement https://codepen.io/designer/pen/abc123

# From local folder
/implement ./examples/feature-demo/

# From gist
/implement https://gist.github.com/expert/useful-snippet
```

### Multiple Sources Examples
```bash
# Combine best parts from multiple implementations
/implement https://github.com/projectA https://gitlab.com/projectB

# Mix local and remote sources
/implement ./my-old-code https://github.com/modern-example

# Blend different approaches
/implement "auth system" https://github.com/secure-auth ./legacy-auth/
```

### Smart Detection Examples
```bash
# Auto-detects full repo clone needed
/implement https://github.com/framework/complete-example

# Auto-detects single file fetch
/implement https://github.com/utils/repo/blob/main/utility-file

# Auto-detects playground structure  
/implement https://jsfiddle.net/expert/a1b2c3/

# Auto-detects local project
/implement ../neighbor-project/src/
```

## Intelligent Adaptation Process

I'll handle various scenarios:
- **Outdated patterns**: Automatically modernize to current standards
- **Security issues**: Fix vulnerabilities during implementation
- **Bloated code**: Extract only essential functionality
- **Incompatible dependencies**: Map to your existing tools
- **Different architectures**: Adapt to your project structure

The key difference: I don't just copy code - I ensure it fits perfectly with your existing setup, uses what you already have, and follows current best practices.

## Implementation Plan Analysis

When working with .md implementation plans, I follow this careful process:

### Understanding Checklist Format
I recognize various checklist formats:
- [ ] Not started task
- [x] Completed task
- [~] Partially completed task
- TODO: Task description
- DONE: Completed task
- WIP: Work in progress

### Verification Process
Before implementing any task:
1. Check if files/functions mentioned already exist
2. Use Grep to search for implementations
3. Read existing code to understand current state
4. Only implement what's actually missing

### Progress Tracking
As I work:
- Update checklist items from [ ] to [x]
- Add notes about what was implemented
- Document any deviations from the plan
- Create clear commit messages referencing plan items

## CRITICAL: Complete Repository Analysis Strategy

When analyzing multiple repositories, I follow this EXHAUSTIVE approach:

### 1. **Complete File Discovery**
Use Glob patterns to find all files in all directories.
Read every file found, regardless of type or location.

### 2. **Systematic Component Reading**
Read every single file found in every directory.
No exceptions, no skipping, complete analysis.

### 3. **Implementation Detail Extraction**
Extract specific implementation details, not generic descriptions.
Understand exact patterns, algorithms, and approaches used.

### 4. **Professional Analysis Output**
Report complete analysis with:
- Total files analyzed
- Core features identified
- Architectural patterns found
- Key implementations to extract

### 5. **Nothing Gets Missed**
- Config files: Read ALL
- Test files: Read to understand usage
- Documentation: Read AFTER code
- Hidden files: Check environment examples, ignore files
- Build files: Understand project setup